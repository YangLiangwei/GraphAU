{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128070, 3)\n",
      "(90022, 3)\n",
      "(70540, 3)\n",
      "(64521, 3)\n",
      "(60015, 3)\n",
      "(58118, 3)\n",
      "(56305, 3)\n",
      "(55491, 3)\n",
      "(54680, 3)\n",
      "(54280, 3)\n",
      "(53913, 3)\n",
      "(53730, 3)\n",
      "(53521, 3)\n",
      "(53445, 3)\n",
      "(53353, 3)\n",
      "(53306, 3)\n",
      "(53274, 3)\n",
      "(53262, 3)\n",
      "(53258, 3)\n",
      "Uniqie data points (53258, 3)\n",
      "Total data samples:  53258\n",
      "User numbers:  4905\n",
      "Item numbers:  2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4905/4905 [00:00<00:00, 156646.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "file = 'office.txt'\n",
    "\n",
    "ls = []\n",
    "\n",
    "with open(file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = line.strip().split(' ')\n",
    "        user = int(line[0])\n",
    "        item = int(line[1])\n",
    "        rating = int(line[2])\n",
    "\n",
    "        ls.append([user, item, rating])\n",
    "data = np.array(ls)\n",
    "\n",
    "def core_filter(data, core = 5):\n",
    "    while True:\n",
    "        mask = []\n",
    "        mask_user = np.bincount(data[:, 0]) > core - 1\n",
    "        mask_item = np.bincount(data[:, 1]) > core - 1\n",
    "\n",
    "        for line in data:\n",
    "            user = line[0]\n",
    "            item = line[1]\n",
    "            mask.append(mask_user[user] and mask_item[item])\n",
    "\n",
    "        data = data[mask]\n",
    "        if sum(mask) == len(mask):\n",
    "            break\n",
    "        print(data.shape)\n",
    "    data = np.unique(data, axis = 0)\n",
    "    print(\"Uniqie data points\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def re_mapping(data):\n",
    "    user_index = 0\n",
    "    item_index = 0\n",
    "    user_mapping = {}\n",
    "    item_mapping = {}\n",
    "    users = data[:, 0]\n",
    "    items = data[:, 1]\n",
    "\n",
    "    for user in users:\n",
    "        if user not in user_mapping:\n",
    "            user_mapping[user] = user_index\n",
    "            user_index += 1\n",
    "\n",
    "    for item in items:\n",
    "        if item not in item_mapping:\n",
    "            item_mapping[item] = item_index\n",
    "            item_index += 1\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i, 0] = user_mapping[data[i, 0]]\n",
    "        data[i, 1] = item_mapping[data[i, 1]]\n",
    "    \n",
    "    print(\"Total data samples: \", len(data))\n",
    "    print(\"User numbers: \", user_index)\n",
    "    print(\"Item numbers: \", item_index)\n",
    "    return data\n",
    "\n",
    "def split_data(data, train_ratio = 0.6):\n",
    "    np.random.shuffle(data)\n",
    "    user_dic = {}\n",
    "    for line in data:\n",
    "        user, item, rating = line\n",
    "        if user in user_dic:\n",
    "            user_dic[user].append([item, rating])\n",
    "        else:\n",
    "            user_dic[user] = [[item, rating]]\n",
    "\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "    val_ratio = (1 - train_ratio) / 2\n",
    "\n",
    "    for user in tqdm(user_dic):\n",
    "        interactions = user_dic[user]\n",
    "        for i in range(int(len(interactions) * train_ratio)):\n",
    "            item, rating = interactions[i]\n",
    "            train_data.append([user, item, rating])\n",
    "\n",
    "        for i in range(int(len(interactions) * train_ratio), int(len(interactions) * (train_ratio + val_ratio))):\n",
    "            item, rating = interactions[i]\n",
    "            val_data.append([user, item, rating])\n",
    "        \n",
    "        for i in range(int(len(interactions) * (train_ratio + val_ratio)), len(interactions)):\n",
    "            item, rating = interactions[i]\n",
    "            if rating > 3:\n",
    "                test_data.append([user, item, rating])\n",
    "\n",
    "    return train_data, val_data, test_data \n",
    "\n",
    "def write_file(data, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for line in data:\n",
    "            user = line[0]\n",
    "            item = line[1]\n",
    "            rating = line[2]\n",
    "            f.write(str(user) + ',' + str(item) + ',' + str(rating))\n",
    "            f.write('\\n')\n",
    "    \n",
    "data = core_filter(data, core = 5)\n",
    "data = re_mapping(data)\n",
    "train, val, test = split_data(data)\n",
    "\n",
    "write_file(train, './train.txt')\n",
    "write_file(val, './val.txt')\n",
    "write_file(test, './test.txt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53258, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data, axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a646f889987aeb6fa979ec1c7d0ee0467467b52c104bc138ed7601e376098c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
